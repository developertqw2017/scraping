2017-10-17 16:22:19 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:22:19 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:22:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:22:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:22:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:22:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:22:19 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:22:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:22:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn/xfyw/index.jhtml> (referer: None)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98317.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98482.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98351.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98485.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98348.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98339.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98522.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98169.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/88109.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/95557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/90132.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51871.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58791.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59826.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:22:21 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68391.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62201.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55809.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70552.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:22:21 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69715.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70401.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93866.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/97237.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93080.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84185.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/90132.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50333.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50421.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59190.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75115.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68913.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59193.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76450.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77148.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82952.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54582.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54486.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68280.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/45464.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59190.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93077.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60945.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51762.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84546.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58632.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49621.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:22 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58940.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52669.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61524.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52476.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:22:23 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93808.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51898.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/85368.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65017.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67376.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56290.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73082.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:22:23 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62710.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54036.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54475.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52005.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84546.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58537.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82044.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55829.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84546.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/86061.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:22:23 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72743.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76046.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76292.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61705.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52669.jhtml)
2017-10-17 16:22:23 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82287.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52638.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57533.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70128.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65017.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67594.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66196.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54585.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69721.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50419.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54039.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:22:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93352.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54030.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:22:24 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51790.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51996.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66798.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75298.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76236.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/82044.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72544.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65851.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/76046.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71353.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54683.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/70128.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64457.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53628.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52416.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/79928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60226.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54354.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70555.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/66196.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54592.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71442.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62096.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70049.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52467.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:22:24 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:24 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55189.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/66798.jhtml)
2017-10-17 16:22:24 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52806.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53807.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51996.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61692.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/75298.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58986.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55141.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73734.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:22:25 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70410.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66448.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53628.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/83978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53628.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61054.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87501.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/94469.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60226.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72536.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72517.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58225.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52389.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84567.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76215.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:22:25 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:25 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53746.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71253.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49751.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64021.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60246.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58283.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62081.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58543.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69667.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75613.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/80604.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51787.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56523.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49429.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54516.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84567.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49615.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68732.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/74047.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68963.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49549.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/91891.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89819.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52885.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52428.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/62081.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52900.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52194.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56293.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53191.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:22:26 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:26 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:26 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60755.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69929.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67915.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53844.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/56523.jhtml)
2017-10-17 16:22:26 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54337.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69130.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67840.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56979.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:22:26 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:26 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75359.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72767.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75780.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54650.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68847.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50641.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:22:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/92129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:22:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57854.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:27 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:22:28 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:22:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 96,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 96,
 'downloader/request_bytes': 88359,
 'downloader/request_count': 279,
 'downloader/request_method_count/GET': 279,
 'downloader/response_bytes': 7309043,
 'downloader/response_count': 183,
 'downloader/response_status_count/200': 183,
 'dupefilter/filtered': 1180,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 22, 28, 903302),
 'log_count/DEBUG': 280,
 'log_count/ERROR': 32,
 'log_count/INFO': 7,
 'log_count/WARNING': 96,
 'memusage/max': 22728704,
 'memusage/startup': 22728704,
 'request_depth_max': 9,
 'response_received_count': 183,
 'retry/count': 64,
 'retry/max_reached': 32,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 64,
 'scheduler/dequeued': 279,
 'scheduler/dequeued/memory': 279,
 'scheduler/enqueued': 279,
 'scheduler/enqueued/memory': 279,
 'start_time': datetime.datetime(2017, 10, 17, 8, 22, 19, 886601)}
2017-10-17 16:22:28 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:34:53 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:34:53 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:34:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:34:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:34:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:34:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:34:53 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:34:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn/xfyw/index.jhtml> (referer: None)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:54 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98317.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98522.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98482.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98348.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98169.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98485.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98351.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98339.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/95557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/88109.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:54 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/90132.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51871.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58791.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59826.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:34:55 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60226.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68391.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70552.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62201.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:34:55 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:55 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54337.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75780.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98169.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93866.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:34:55 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:55 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84185.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/90132.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68963.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:34:55 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:55 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53191.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59190.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:34:55 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68913.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:34:55 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/94469.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60226.jhtml)
2017-10-17 16:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50333.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50421.jhtml)
2017-10-17 16:34:55 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:55 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77148.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75115.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:34:56 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82952.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:34:56 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76450.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54486.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51762.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59193.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54582.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68280.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58940.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:34:56 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/45464.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59190.jhtml)
2017-10-17 16:34:56 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58632.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61705.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/94469.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49621.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67376.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82044.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72743.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76046.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52669.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/86061.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82287.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:34:56 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61524.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73082.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:34:56 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93808.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52476.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51898.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/85368.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65017.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54036.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:34:56 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56290.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89819.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/74047.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52194.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62710.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51790.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70049.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98169.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65851.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/76046.jhtml)
2017-10-17 16:34:57 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76236.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/82044.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71442.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98169.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67594.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72544.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93352.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52467.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98169.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/91891.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98169.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68732.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98169.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52638.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70128.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65017.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69715.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70401.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68847.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72767.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75359.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54585.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64457.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/74047.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51787.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66448.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/74047.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49429.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:34:57 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:57 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52806.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58986.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/80604.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58225.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58543.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49615.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66196.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49549.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50419.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54683.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/70128.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69667.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69721.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:34:58 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72517.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72536.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70410.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50641.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54030.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57854.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52005.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84546.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61054.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67915.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60755.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/92129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54039.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69130.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67840.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93080.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70555.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/66196.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56979.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/97237.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54650.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:34:58 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:58 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:58 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76292.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55809.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57533.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71353.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53628.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60945.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84546.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52416.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/79928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55829.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84546.jhtml)
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93077.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54475.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84567.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58537.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73734.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/83978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53628.jhtml)
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55141.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:34:59 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:34:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87501.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54516.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84567.jhtml)
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54592.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54354.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62096.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66798.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60246.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71253.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49751.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75298.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51996.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55189.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54354.jhtml)
2017-10-17 16:35:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61692.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/75298.jhtml)
2017-10-17 16:35:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53807.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51996.jhtml)
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52389.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75613.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76215.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56523.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62081.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58283.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53746.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64021.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69929.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53844.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/56523.jhtml)
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52428.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/62081.jhtml)
2017-10-17 16:35:02 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:02 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52885.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52900.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56293.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:35:02 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:02 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:02 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:35:02 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:35:02 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:35:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 96,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 96,
 'downloader/request_bytes': 88359,
 'downloader/request_count': 279,
 'downloader/request_method_count/GET': 279,
 'downloader/response_bytes': 7309043,
 'downloader/response_count': 183,
 'downloader/response_status_count/200': 183,
 'dupefilter/filtered': 1180,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 35, 2, 306928),
 'log_count/DEBUG': 280,
 'log_count/ERROR': 32,
 'log_count/INFO': 7,
 'log_count/WARNING': 96,
 'memusage/max': 22745088,
 'memusage/startup': 22745088,
 'request_depth_max': 12,
 'response_received_count': 183,
 'retry/count': 64,
 'retry/max_reached': 32,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 64,
 'scheduler/dequeued': 279,
 'scheduler/dequeued/memory': 279,
 'scheduler/enqueued': 279,
 'scheduler/enqueued/memory': 279,
 'start_time': datetime.datetime(2017, 10, 17, 8, 34, 53, 521210)}
2017-10-17 16:35:02 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:38:28 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:38:28 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:38:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:38:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:38:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:38:28 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:38:28 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:38:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn/xfyw/index.jhtml> (referer: None)
2017-10-17 16:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98317.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98482.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98522.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98351.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98348.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98485.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98169.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98339.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/95557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/88109.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/90132.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51871.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58791.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:38:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59826.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70552.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:38:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62201.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60226.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68391.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55809.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75780.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71442.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93866.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70049.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67376.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:38:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68963.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73082.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82044.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:38:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59190.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:38:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82952.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/94469.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60226.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77148.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:38:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75115.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50333.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50421.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76450.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54486.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68913.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:38:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59193.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54582.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68280.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76236.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/82044.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67594.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93352.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51762.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:38:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58632.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/45464.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59190.jhtml)
2017-10-17 16:38:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58940.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61705.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/94469.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52669.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49621.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76046.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:38:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/86061.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72743.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84185.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/90132.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82287.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61524.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93808.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52476.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52638.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:38:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/85368.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54036.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62710.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64457.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65017.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:38:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66196.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52467.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56290.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/91891.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51898.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:38:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72544.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51790.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65851.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/76046.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/74047.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68732.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69715.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70401.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:38:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50419.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69721.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54030.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70410.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72536.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54585.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70128.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65017.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72517.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54039.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70555.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/66196.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51787.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58986.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58225.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49429.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/80604.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66448.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/74047.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69667.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58543.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49615.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49549.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:38:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52806.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54683.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/70128.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53191.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52194.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93080.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:38:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/97237.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89819.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76292.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57533.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54337.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67840.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56979.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69130.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67915.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:38:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60755.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84546.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54650.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61054.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52005.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75359.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93077.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60945.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68847.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72767.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55829.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84546.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52416.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/79928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53628.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54475.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71353.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58537.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50641.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57854.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/92129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73734.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87501.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55141.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84567.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53628.jhtml)
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54592.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/83978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53628.jhtml)
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75298.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66798.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51996.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54354.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62096.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60246.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54516.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84567.jhtml)
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49751.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71253.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:35 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53807.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51996.jhtml)
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61692.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/75298.jhtml)
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55189.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/66798.jhtml)
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56523.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53746.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64021.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62081.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58283.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52389.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53844.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/56523.jhtml)
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75613.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76215.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52885.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56293.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52428.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/62081.jhtml)
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 16:38:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52900.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:36 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:37 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:37 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:37 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69929.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 16:38:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:37 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:38:37 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:38:37 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:38:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 96,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 96,
 'downloader/request_bytes': 88359,
 'downloader/request_count': 279,
 'downloader/request_method_count/GET': 279,
 'downloader/response_bytes': 7309043,
 'downloader/response_count': 183,
 'downloader/response_status_count/200': 183,
 'dupefilter/filtered': 1180,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 38, 37, 425625),
 'log_count/DEBUG': 280,
 'log_count/ERROR': 32,
 'log_count/INFO': 7,
 'log_count/WARNING': 96,
 'memusage/max': 22847488,
 'memusage/startup': 22847488,
 'request_depth_max': 9,
 'response_received_count': 183,
 'retry/count': 64,
 'retry/max_reached': 32,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 64,
 'scheduler/dequeued': 279,
 'scheduler/dequeued/memory': 279,
 'scheduler/enqueued': 279,
 'scheduler/enqueued/memory': 279,
 'start_time': datetime.datetime(2017, 10, 17, 8, 38, 28, 824022)}
2017-10-17 16:38:37 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:40:09 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:40:09 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:40:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:40:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:40:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:40:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:40:09 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:40:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn/xfyw/index.jhtml> (referer: None)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98317.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98482.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98522.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98485.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98351.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98348.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98339.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98169.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/88109.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/95557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/90132.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51871.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58791.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59826.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68391.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70552.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62201.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55809.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68963.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75780.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53191.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93866.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61524.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59190.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68913.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77148.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76450.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50333.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50421.jhtml)
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75115.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68280.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82952.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:40:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59193.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:40:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61705.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/61524.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58940.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58632.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51762.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54486.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:40:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/45464.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59190.jhtml)
2017-10-17 16:40:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49621.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52669.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54582.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:40:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84185.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/90132.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51898.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52476.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/85368.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82044.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73082.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56290.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93808.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72743.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:40:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76046.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67376.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65017.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/86061.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54036.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62710.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69715.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50419.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54030.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70401.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69721.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82287.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54039.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:40:14 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67594.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65851.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/76046.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76236.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/82044.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93352.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51790.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89819.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52194.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52638.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72544.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71442.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66196.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54585.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70049.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52467.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70128.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65017.jhtml)
2017-10-17 16:40:14 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93080.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70555.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50419.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68732.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/91891.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/74047.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:40:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/97237.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75359.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58225.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49615.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51787.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68847.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49549.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49429.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:40:15 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/80604.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54683.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/70128.jhtml)
2017-10-17 16:40:15 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52806.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58986.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58543.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84546.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60945.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64457.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69667.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72767.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93077.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76292.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57533.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54337.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66448.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/74047.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69130.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56979.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67840.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60226.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54650.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60755.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67915.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:40:15 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61054.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52005.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54475.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58537.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 16:40:15 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:15 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:15 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55829.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84546.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70410.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57854.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/92129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50641.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72536.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72517.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/94469.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60226.jhtml)
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51996.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75298.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66798.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54592.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62096.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/79928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71353.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53628.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52416.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54354.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:40:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55189.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/66798.jhtml)
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53807.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51996.jhtml)
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61692.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/75298.jhtml)
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73734.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/83978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53628.jhtml)
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55141.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:40:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84567.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87501.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:40:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62081.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:40:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53746.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60246.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56523.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64021.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58283.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52389.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71253.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49751.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76215.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75613.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54516.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84567.jhtml)
2017-10-17 16:40:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52428.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/62081.jhtml)
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52885.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56293.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52900.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53844.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/56523.jhtml)
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69929.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:40:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:40:19 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:40:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 96,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 96,
 'downloader/request_bytes': 88359,
 'downloader/request_count': 279,
 'downloader/request_method_count/GET': 279,
 'downloader/response_bytes': 7309043,
 'downloader/response_count': 183,
 'downloader/response_status_count/200': 183,
 'dupefilter/filtered': 1180,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 40, 19, 149638),
 'log_count/DEBUG': 280,
 'log_count/ERROR': 32,
 'log_count/INFO': 7,
 'log_count/WARNING': 96,
 'memusage/max': 22671360,
 'memusage/startup': 22671360,
 'request_depth_max': 9,
 'response_received_count': 183,
 'retry/count': 64,
 'retry/max_reached': 32,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 64,
 'scheduler/dequeued': 279,
 'scheduler/dequeued/memory': 279,
 'scheduler/enqueued': 279,
 'scheduler/enqueued/memory': 279,
 'start_time': datetime.datetime(2017, 10, 17, 8, 40, 9, 365242)}
2017-10-17 16:40:19 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:51:27 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:51:27 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:51:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:51:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:51:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:51:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:51:27 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:51:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:51:27 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.html> (referer: None)
2017-10-17 16:51:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.enshi.gov.cn/zzf/xw/esxw/1.html>: HTTP status code is not handled or not allowed
2017-10-17 16:51:27 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:51:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 495,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 51, 27, 957917),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 8,
 'memusage/max': 22781952,
 'memusage/startup': 22781952,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 10, 17, 8, 51, 27, 768130)}
2017-10-17 16:51:27 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:52:27 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:52:27 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:52:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:52:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:52:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:52:28 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:52:28 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:52:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:52:28 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.html> (referer: None)
2017-10-17 16:52:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.enshi.gov.cn/zzf/xw/esxw/1.html>: HTTP status code is not handled or not allowed
2017-10-17 16:52:28 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:52:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 495,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 52, 28, 259768),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 8,
 'memusage/max': 22491136,
 'memusage/startup': 22491136,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 10, 17, 8, 52, 28, 53575)}
2017-10-17 16:52:28 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:52:57 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:52:57 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:52:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:52:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:52:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:52:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:52:57 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:52:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:52:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.html> (referer: None)
2017-10-17 16:52:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.enshi.gov.cn/zzf/xw/esxw/1.html>: HTTP status code is not handled or not allowed
2017-10-17 16:52:57 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:52:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 495,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 52, 57, 357143),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 8,
 'memusage/max': 22597632,
 'memusage/startup': 22597632,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 10, 17, 8, 52, 57, 148417)}
2017-10-17 16:52:57 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:53:25 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:53:25 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:53:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:53:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:53:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:53:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:53:25 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:53:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:53:25 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.html> (referer: None)
2017-10-17 16:53:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.enshi.gov.cn/zzf/xw/esxw/1.html>: HTTP status code is not handled or not allowed
2017-10-17 16:53:25 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:53:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 495,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 53, 25, 736598),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 8,
 'memusage/max': 22573056,
 'memusage/startup': 22573056,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 10, 17, 8, 53, 25, 505239)}
2017-10-17 16:53:25 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:53:49 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:53:49 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:53:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:53:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:53:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:53:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:53:49 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:53:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:53:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn/xfyw/index.jhtml> (referer: None)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98317.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98482.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98522.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98485.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98348.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98351.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98339.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98169.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/88109.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/90132.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/95557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51871.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58791.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:53:50 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59826.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68391.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62201.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:53:50 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70552.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68963.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:53:51 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52194.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53191.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55809.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93866.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:53:51 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51762.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89819.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:53:51 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58940.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77148.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58632.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50333.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50421.jhtml)
2017-10-17 16:53:51 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59190.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75115.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:53:51 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:51 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:51 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:51 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82952.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59193.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:53:51 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68913.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 16:53:51 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76450.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52669.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52476.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61524.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/85368.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93808.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/45464.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59190.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72767.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75359.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68847.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49621.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:53:52 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51898.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:53:52 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84185.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/90132.jhtml)
2017-10-17 16:53:52 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56290.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68280.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54486.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:53:52 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73082.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54582.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:53:52 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82044.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72743.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61705.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52669.jhtml)
2017-10-17 16:53:52 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67376.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:53:52 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/92129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57854.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65017.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50641.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:53:52 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62710.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76046.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82287.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/86061.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:53:52 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54036.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69715.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51790.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67594.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:53:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72544.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76236.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/82044.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50419.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54039.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54030.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93352.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70128.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65017.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52638.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69721.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70401.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65851.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/76046.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54585.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66196.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70049.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71442.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52806.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58986.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52467.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64457.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51787.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49429.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49615.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/91891.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49549.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:53:53 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70555.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50419.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93080.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54683.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/70128.jhtml)
2017-10-17 16:53:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68732.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/74047.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/97237.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57533.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69667.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76292.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60226.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/80604.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58543.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58225.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75780.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:53:54 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84546.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70410.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72536.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72517.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:53:54 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52005.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61054.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93077.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69130.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67840.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56979.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54337.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66448.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/74047.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60945.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:53:54 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:53:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67915.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60755.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/94469.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60226.jhtml)
2017-10-17 16:53:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54650.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:53:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 25,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 25,
 'downloader/request_bytes': 51904,
 'downloader/request_count': 164,
 'downloader/request_method_count/GET': 164,
 'downloader/response_bytes': 5602576,
 'downloader/response_count': 139,
 'downloader/response_status_count/200': 139,
 'dupefilter/filtered': 879,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 53, 55, 53378),
 'log_count/DEBUG': 165,
 'log_count/INFO': 8,
 'log_count/WARNING': 25,
 'memusage/max': 22691840,
 'memusage/startup': 22691840,
 'request_depth_max': 8,
 'response_received_count': 139,
 'retry/count': 25,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 25,
 'scheduler/dequeued': 164,
 'scheduler/dequeued/memory': 164,
 'scheduler/enqueued': 198,
 'scheduler/enqueued/memory': 198,
 'start_time': datetime.datetime(2017, 10, 17, 8, 53, 49, 92575)}
2017-10-17 16:53:55 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-10-17 16:53:56 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:53:56 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:53:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:53:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:53:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:53:56 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:53:56 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:53:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:53:56 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.html> (referer: None)
2017-10-17 16:53:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.enshi.gov.cn/zzf/xw/esxw/1.html>: HTTP status code is not handled or not allowed
2017-10-17 16:53:57 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:53:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 495,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 53, 57, 34879),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 8,
 'memusage/max': 22519808,
 'memusage/startup': 22519808,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 10, 17, 8, 53, 56, 848203)}
2017-10-17 16:53:57 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:56:17 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:56:17 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:56:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:56:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:56:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:56:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:56:17 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:56:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:56:17 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.html> (referer: None)
2017-10-17 16:56:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.enshi.gov.cn/zzf/xw/esxw/1.html>: HTTP status code is not handled or not allowed
2017-10-17 16:56:17 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:56:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 495,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 56, 17, 712116),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 8,
 'memusage/max': 22683648,
 'memusage/startup': 22683648,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 10, 17, 8, 56, 17, 528032)}
2017-10-17 16:56:17 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:57:16 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:57:16 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:57:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:57:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:57:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:57:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:57:16 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:57:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:57:16 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.html> (referer: None)
2017-10-17 16:57:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.enshi.gov.cn/zzf/xw/esxw/1.html>: HTTP status code is not handled or not allowed
2017-10-17 16:57:17 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:57:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 495,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 57, 17, 87368),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 8,
 'memusage/max': 22671360,
 'memusage/startup': 22671360,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 10, 17, 8, 57, 16, 896742)}
2017-10-17 16:57:17 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:57:26 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:57:26 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:57:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:57:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:57:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:57:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:57:26 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:57:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn/xfyw/index.jhtml> (referer: None)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/95557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98317.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98482.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98351.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98339.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98348.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98169.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98522.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xianfeng.gov.cn:80/xfyw/67981.jhtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/88109.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98485.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/90132.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52476.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/85368.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51898.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:57:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61524.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93808.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56290.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:57:27 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71442.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98169.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70049.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98169.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68963.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62201.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70401.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73082.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93866.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69715.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/74047.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67376.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82044.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84185.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/90132.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72743.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:57:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61705.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/61524.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77148.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/86061.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82952.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76450.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 16:57:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76046.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:57:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82287.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 16:57:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93080.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/97237.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93352.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64457.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/74047.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51790.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62710.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/74047.jhtml)
2017-10-17 16:57:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67594.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 16:57:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76236.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/82044.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72544.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75115.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/82044.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66448.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/74047.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60226.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76292.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57533.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84546.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60945.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50419.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93077.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65851.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/76046.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69721.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:57:29 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54030.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70410.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51787.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72517.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72536.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52638.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:57:29 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58986.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:57:29 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52806.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54036.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/76292.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/94469.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60226.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54475.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69667.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58225.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58543.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70555.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50419.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55829.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84546.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/80604.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 16:57:29 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65017.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58537.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52005.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84546.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58940.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84546.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/45464.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/62710.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61054.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49429.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:57:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59193.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 16:57:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49615.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54585.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49549.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54039.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66196.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93352.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54592.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62096.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70128.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65017.jhtml)
2017-10-17 16:57:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60755.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52416.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67915.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52467.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98339.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/79928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53628.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59190.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75298.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54354.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51996.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71353.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66798.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 16:57:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89819.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/91891.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98339.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52194.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53191.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68732.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98339.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75780.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98339.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73734.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87501.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54683.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/70128.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69130.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54337.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55141.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56979.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:57:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67840.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:57:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55189.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54354.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53807.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51996.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61692.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/75298.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68847.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49751.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75359.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71253.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84567.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53628.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72767.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60246.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/83978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53628.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54650.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:57:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68280.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54486.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70552.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62081.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:57:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52389.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:57:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56523.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58283.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53746.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64021.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50641.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/92129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75613.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76215.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54582.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54516.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84567.jhtml)
2017-10-17 16:57:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57854.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51871.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:57:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59826.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:57:31 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58791.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68391.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55809.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53844.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/56523.jhtml)
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56293.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52428.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/62081.jhtml)
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68913.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/56523.jhtml)
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52900.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52885.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51762.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69929.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52669.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58632.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50333.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50421.jhtml)
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:32 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49621.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:33 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:34 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:34 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:34 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 16:57:34 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 16:57:34 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:57:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 96,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 96,
 'downloader/request_bytes': 88359,
 'downloader/request_count': 279,
 'downloader/request_method_count/GET': 279,
 'downloader/response_bytes': 7309043,
 'downloader/response_count': 183,
 'downloader/response_status_count/200': 183,
 'dupefilter/filtered': 998,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 57, 34, 222102),
 'log_count/DEBUG': 280,
 'log_count/ERROR': 32,
 'log_count/INFO': 7,
 'log_count/WARNING': 96,
 'memusage/max': 22659072,
 'memusage/startup': 22659072,
 'request_depth_max': 9,
 'response_received_count': 183,
 'retry/count': 64,
 'retry/max_reached': 32,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 64,
 'scheduler/dequeued': 279,
 'scheduler/dequeued/memory': 279,
 'scheduler/enqueued': 279,
 'scheduler/enqueued/memory': 279,
 'start_time': datetime.datetime(2017, 10, 17, 8, 57, 26, 241448)}
2017-10-17 16:57:34 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:57:37 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:57:37 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:57:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:57:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:57:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:57:37 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:57:37 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:57:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:57:37 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.html> (referer: None)
2017-10-17 16:57:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.enshi.gov.cn/zzf/xw/esxw/1.html>: HTTP status code is not handled or not allowed
2017-10-17 16:57:37 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:57:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 495,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 57, 37, 276861),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 8,
 'memusage/max': 22659072,
 'memusage/startup': 22659072,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 10, 17, 8, 57, 37, 96199)}
2017-10-17 16:57:37 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:58:20 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:58:20 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:58:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:58:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:58:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:58:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:58:20 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:58:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:58:20 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.html> (referer: None)
2017-10-17 16:58:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.enshi.gov.cn/zzf/xw/esxw/1.html>: HTTP status code is not handled or not allowed
2017-10-17 16:58:20 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:58:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 495,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 58, 20, 652789),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 8,
 'memusage/max': 22659072,
 'memusage/startup': 22659072,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 10, 17, 8, 58, 20, 453552)}
2017-10-17 16:58:20 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 16:58:41 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 16:58:41 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 16:58:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 16:58:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 16:58:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 16:58:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 16:58:41 [scrapy.core.engine] INFO: Spider opened
2017-10-17 16:58:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 16:58:41 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.html> (referer: None)
2017-10-17 16:58:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.enshi.gov.cn/zzf/xw/esxw/1.html>: HTTP status code is not handled or not allowed
2017-10-17 16:58:41 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 16:58:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 495,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 8, 58, 41, 363067),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 8,
 'memusage/max': 22618112,
 'memusage/startup': 22618112,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 10, 17, 8, 58, 41, 180882)}
2017-10-17 16:58:41 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:07:13 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:07:13 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:07:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:07:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:07:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:07:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:07:13 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:07:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584407.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584407.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:07:23 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:07:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 54726,
 'downloader/request_count': 189,
 'downloader/request_method_count/GET': 189,
 'downloader/response_bytes': 1047018,
 'downloader/response_count': 189,
 'downloader/response_status_count/200': 189,
 'dupefilter/filtered': 88,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 7, 23, 620974),
 'log_count/DEBUG': 190,
 'log_count/ERROR': 149,
 'log_count/INFO': 7,
 'memusage/max': 22679552,
 'memusage/startup': 22679552,
 'request_depth_max': 4,
 'response_received_count': 189,
 'scheduler/dequeued': 189,
 'scheduler/dequeued/memory': 189,
 'scheduler/enqueued': 189,
 'scheduler/enqueued/memory': 189,
 'spider_exceptions/AttributeError': 149,
 'start_time': datetime.datetime(2017, 10, 17, 9, 7, 13, 668471)}
2017-10-17 17:07:23 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:11:55 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:11:55 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:11:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:11:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:11:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:11:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:11:55 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:11:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:11:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584407.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584407.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:11:58 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:11:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 54726,
 'downloader/request_count': 189,
 'downloader/request_method_count/GET': 189,
 'downloader/response_bytes': 1047018,
 'downloader/response_count': 189,
 'downloader/response_status_count/200': 189,
 'dupefilter/filtered': 86,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 11, 58, 231151),
 'log_count/DEBUG': 190,
 'log_count/ERROR': 151,
 'log_count/INFO': 7,
 'memusage/max': 22609920,
 'memusage/startup': 22609920,
 'request_depth_max': 4,
 'response_received_count': 189,
 'scheduler/dequeued': 189,
 'scheduler/dequeued/memory': 189,
 'scheduler/enqueued': 189,
 'scheduler/enqueued/memory': 189,
 'spider_exceptions/AttributeError': 151,
 'start_time': datetime.datetime(2017, 10, 17, 9, 11, 55, 775660)}
2017-10-17 17:11:58 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:13:22 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:13:22 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:13:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:13:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:13:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:13:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:13:22 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:13:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:13:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:13:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584407.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584407.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:13:25 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:13:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 54726,
 'downloader/request_count': 189,
 'downloader/request_method_count/GET': 189,
 'downloader/response_bytes': 1047018,
 'downloader/response_count': 189,
 'downloader/response_status_count/200': 189,
 'dupefilter/filtered': 90,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 13, 25, 246327),
 'log_count/DEBUG': 190,
 'log_count/ERROR': 147,
 'log_count/INFO': 7,
 'memusage/max': 22650880,
 'memusage/startup': 22650880,
 'request_depth_max': 4,
 'response_received_count': 189,
 'scheduler/dequeued': 189,
 'scheduler/dequeued/memory': 189,
 'scheduler/enqueued': 189,
 'scheduler/enqueued/memory': 189,
 'spider_exceptions/AttributeError': 147,
 'start_time': datetime.datetime(2017, 10, 17, 9, 13, 22, 513658)}
2017-10-17 17:13:25 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:14:22 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:14:22 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:14:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:14:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:14:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:14:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:14:22 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:14:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584407.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584407.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 56, in parse_1
    print(response.xpath('//div[@class="article-infos"]/span').text().extract())
AttributeError: 'SelectorList' object has no attribute 'text'
2017-10-17 17:14:24 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:14:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 54726,
 'downloader/request_count': 189,
 'downloader/request_method_count/GET': 189,
 'downloader/response_bytes': 1047018,
 'downloader/response_count': 189,
 'downloader/response_status_count/200': 189,
 'dupefilter/filtered': 81,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 14, 24, 790524),
 'log_count/DEBUG': 190,
 'log_count/ERROR': 156,
 'log_count/INFO': 7,
 'memusage/max': 22417408,
 'memusage/startup': 22417408,
 'request_depth_max': 4,
 'response_received_count': 189,
 'scheduler/dequeued': 189,
 'scheduler/dequeued/memory': 189,
 'scheduler/enqueued': 189,
 'scheduler/enqueued/memory': 189,
 'spider_exceptions/AttributeError': 156,
 'start_time': datetime.datetime(2017, 10, 17, 9, 14, 22, 303392)}
2017-10-17 17:14:24 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:15:11 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:15:11 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:15:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:15:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:15:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:15:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:15:11 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:15:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn/xfyw/index.jhtml> (referer: None)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98495.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98317.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98482.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98351.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98485.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98522.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98169.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98348.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98339.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/88109.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:12 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xianfeng.gov.cn:80/xfyw/75780.jhtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51871.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/90132.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/95557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59826.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 17:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/98426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68391.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69130.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56979.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67840.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54337.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58791.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98495.jhtml)
2017-10-17 17:15:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93080.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/97237.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57533.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59557.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 17:15:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68280.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 17:15:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69715.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93866.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/index.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70401.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50333.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50421.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54486.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/45464.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/56979.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61705.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67840.jhtml)
2017-10-17 17:15:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54582.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98426.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93077.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84546.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60945.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/93080.jhtml)
2017-10-17 17:15:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:13 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59190.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61524.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 17:15:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75115.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/59193.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84185.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/90132.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68913.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/59826.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51898.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/85368.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49621.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93808.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52271.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65017.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52476.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54036.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54475.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52005.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84546.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62710.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/45464.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58537.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60945.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55829.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84546.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/50333.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51762.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 17:15:14 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:14 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56290.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/95557.jhtml)
2017-10-17 17:15:14 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58940.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58632.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52669.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51871.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52638.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70128.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65017.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73082.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82044.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67376.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66196.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54592.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54585.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52271.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54354.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62096.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54475.jhtml)
2017-10-17 17:15:14 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:14 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75298.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66798.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52416.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51996.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/58537.jhtml)
2017-10-17 17:15:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/79928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72743.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53628.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76046.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77421.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71353.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/86061.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67594.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52005.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54683.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/70128.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/93352.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73082.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76236.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/82044.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70555.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/66196.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82287.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/88109.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49426.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 17:15:15 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55189.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54354.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69721.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53807.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51996.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/73734.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 17:15:15 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/87501.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55141.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/52416.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/65851.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/76046.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61054.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 17:15:15 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51981.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/71353.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/61692.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/75298.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49615.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/77421.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/84567.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53628.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64457.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/67594.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/83978.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53628.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72544.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/66448.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53628.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52389.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51790.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72743.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75613.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50419.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76215.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60246.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71253.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/80604.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49751.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/73734.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58225.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58543.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 17:15:15 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69667.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/65851.jhtml)
2017-10-17 17:15:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53746.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72517.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72536.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70410.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/64021.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58986.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51787.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75855.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/64457.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49429.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 17:15:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50745.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54516.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/84567.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52806.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72544.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/49549.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51790.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62081.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58283.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56523.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53807.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/55189.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/67915.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54030.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/56293.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52885.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60755.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/80604.jhtml)
2017-10-17 17:15:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52900.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/53746.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76292.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/60226.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98522.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54039.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98348.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70049.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52467.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/71442.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68732.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/74047.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52428.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/62081.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 17:15:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:16 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/91891.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 17:15:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75780.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98485.jhtml)
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58928.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/69929.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/54824.jhtml)
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53844.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/56523.jhtml)
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/89819.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/52194.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/53191.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68963.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/94469.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/60226.jhtml)
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/58824.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98351.jhtml)
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/70552.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/51837.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/55809.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/62201.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98317.jhtml)
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/54650.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/98482.jhtml)
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/72767.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/75359.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/68847.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/89819.jhtml)
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/77148.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/76450.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 17:15:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/82952.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/51837.jhtml)
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/50641.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 17:15:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/92129.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 17:15:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xianfeng.gov.cn:80/xfyw/57854.jhtml> (referer: http://www.xianfeng.gov.cn/xfyw/72767.jhtml)
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 2 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52918.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58680.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55153.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57182.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52380.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57267.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56770.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59737.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58735.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55839.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58402.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64585.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/55812.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/57536.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49424.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/49419.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52229.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/54069.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56672.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/64032.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58421.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/59222.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58070.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58481.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2017-10-17 17:15:19 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml> (failed 3 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/53699.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58417.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56785.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/50389.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/61451.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/58689.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/52671.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.xianfeng.gov.cn:80/xfyw/56773.jhtml>: [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionDone'>>, <twisted.python.failure.Failure <class 'twisted.web.http._DataLoss'>>]
2017-10-17 17:15:19 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:15:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 96,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 96,
 'downloader/request_bytes': 88359,
 'downloader/request_count': 279,
 'downloader/request_method_count/GET': 279,
 'downloader/response_bytes': 7309043,
 'downloader/response_count': 183,
 'downloader/response_status_count/200': 183,
 'dupefilter/filtered': 998,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 15, 19, 306979),
 'log_count/DEBUG': 280,
 'log_count/ERROR': 32,
 'log_count/INFO': 7,
 'log_count/WARNING': 96,
 'memusage/max': 22593536,
 'memusage/startup': 22593536,
 'request_depth_max': 9,
 'response_received_count': 183,
 'retry/count': 64,
 'retry/max_reached': 32,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 64,
 'scheduler/dequeued': 279,
 'scheduler/dequeued/memory': 279,
 'scheduler/enqueued': 279,
 'scheduler/enqueued/memory': 279,
 'start_time': datetime.datetime(2017, 10, 17, 9, 15, 11, 455113)}
2017-10-17 17:15:19 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:16:32 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:16:32 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:16:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:16:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:16:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:16:32 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:16:32 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:16:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584407.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:16:37 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:16:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62676,
 'downloader/request_count': 216,
 'downloader/request_method_count/GET': 216,
 'downloader/response_bytes': 1195178,
 'downloader/response_count': 216,
 'downloader/response_status_count/200': 216,
 'dupefilter/filtered': 621,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 16, 37, 356258),
 'log_count/DEBUG': 217,
 'log_count/INFO': 7,
 'memusage/max': 22593536,
 'memusage/startup': 22593536,
 'request_depth_max': 7,
 'response_received_count': 216,
 'scheduler/dequeued': 216,
 'scheduler/dequeued/memory': 216,
 'scheduler/enqueued': 216,
 'scheduler/enqueued/memory': 216,
 'start_time': datetime.datetime(2017, 10, 17, 9, 16, 32, 646974)}
2017-10-17 17:16:37 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:17:54 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:17:54 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:17:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:17:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:17:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:17:54 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:17:54 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:17:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:17:58 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:17:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 17, 58, 896640),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22601728,
 'memusage/startup': 22601728,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 9, 17, 54, 581665)}
2017-10-17 17:17:58 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:22:42 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:22:42 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:22:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:22:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:22:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:22:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:22:42 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:22:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:22:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:22:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:22:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:22:47 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:22:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 22, 47, 214711),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22704128,
 'memusage/startup': 22704128,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 9, 22, 42, 770797)}
2017-10-17 17:22:47 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:25:30 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:25:30 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:25:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:25:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:25:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:25:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:25:30 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:25:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:25:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:25:34 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:25:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 25, 34, 586627),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22622208,
 'memusage/startup': 22622208,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 9, 25, 30, 312043)}
2017-10-17 17:25:34 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:35:34 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:35:34 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:35:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:35:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:35:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:35:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:35:34 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:35:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:35:39 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:35:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 35, 39, 61596),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22454272,
 'memusage/startup': 22454272,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 9, 35, 34, 509387)}
2017-10-17 17:35:39 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:36:11 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:36:11 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:36:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:36:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:36:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:36:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:36:11 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:36:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:15 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:36:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 36, 15, 892698),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22609920,
 'memusage/startup': 22609920,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 9, 36, 11, 645806)}
2017-10-17 17:36:15 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:36:32 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:36:32 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:36:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:36:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:36:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:36:33 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:36:33 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:36:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:36:37 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:36:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 36, 37, 357129),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22577152,
 'memusage/startup': 22577152,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 9, 36, 33, 31436)}
2017-10-17 17:36:37 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:39:29 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:39:29 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:39:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:39:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:39:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:39:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:39:29 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:39:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-09 08:27:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 08:47:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 08:56:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 07:47:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 07:51:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 07:54:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 08:38:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 08:05:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 08:10:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 08:41:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 09:30:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 07:45:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 07:58:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 08:07:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 08:16:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 08:11:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 08:19:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 08:23:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 08:32:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 08:44:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 08:41:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-27 08:46:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 08:16:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 08:38:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 08:34:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 08:45:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 08:49:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 08:55:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 08:52:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 08:58:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-28 08:59:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 07:45:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 07:52:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 08:01:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 07:55:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 08:18:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 08:22:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 08:35:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 08:46:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 09:00:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 08:49:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 22:15:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 22:13:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 22:21:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 22:24:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 22:30:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 22:52:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 23:01:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 22:53:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 23:18:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 23:28:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 23:33:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-30 23:04:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-01 22:07:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-01 22:11:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-09 08:10:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-03 16:01:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-09 08:29:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-09 08:14:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 07:55:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 08:01:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 08:05:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 08:14:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 08:22:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 08:18:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 08:27:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 08:32:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 10:34:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-11 07:59:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 08:44:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 08:34:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-10 08:51:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-11 08:03:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-11 08:09:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-11 08:06:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-29 08:57:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-09 08:18:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-11 08:10:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-13 08:31:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-14 08:14:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-13 08:34:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-14 09:19:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-14 09:23:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-14 09:29:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-10-14 09:26:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 08:21:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-25 07:49:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-23 11:34:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-25 07:55:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-25 08:02:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-25 08:07:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-25 08:10:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-25 08:24:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-25 08:16:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-25 08:32:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-25 08:28:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-25 08:42:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-25 08:46:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 07:56:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 07:50:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-21 08:06:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-21 08:04:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-21 08:11:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-21 08:08:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-21 08:15:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-22 08:01:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-22 07:56:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-22 08:05:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-22 08:09:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-22 08:14:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-22 08:21:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-22 08:19:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-23 08:43:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-23 08:50:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-23 08:46:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-23 08:53:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-20 07:59:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-20 08:01:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-18 08:43:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-19 07:57:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-19 08:00:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-19 08:03:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-19 08:06:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-19 08:08:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-19 08:12:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-19 19:50:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-20 07:54:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-20 08:04:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-20 08:06:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-20 08:09:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-20 08:18:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-20 08:21:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-20 08:39:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-20 08:29:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-20 08:42:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-21 07:55:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-23 08:55:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-23 09:00:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-23 09:16:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 07:59:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 08:02:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 08:07:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 08:12:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 08:15:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 59, in parse_1
    time = datetime.now() - datetime.strptime(time,'%Y-%m-%d %H-%M-%S')
  File "/usr/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '2017-09-26 08:17:00' does not match format '%Y-%m-%d %H-%M-%S'
2017-10-17 17:39:32 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:39:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 54436,
 'downloader/request_count': 188,
 'downloader/request_method_count/GET': 188,
 'downloader/response_bytes': 1042669,
 'downloader/response_count': 188,
 'downloader/response_status_count/200': 188,
 'dupefilter/filtered': 90,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 39, 32, 116839),
 'log_count/DEBUG': 189,
 'log_count/ERROR': 145,
 'log_count/INFO': 7,
 'memusage/max': 22421504,
 'memusage/startup': 22421504,
 'request_depth_max': 4,
 'response_received_count': 188,
 'scheduler/dequeued': 188,
 'scheduler/dequeued/memory': 188,
 'scheduler/enqueued': 188,
 'scheduler/enqueued/memory': 188,
 'spider_exceptions/ValueError': 145,
 'start_time': datetime.datetime(2017, 10, 17, 9, 39, 29, 580778)}
2017-10-17 17:39:32 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 17:40:17 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 17:40:17 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 17:40:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 17:40:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 17:40:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 17:40:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 17:40:17 [scrapy.core.engine] INFO: Spider opened
2017-10-17 17:40:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 17:40:21 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 17:40:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 9, 40, 21, 289890),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22609920,
 'memusage/startup': 22609920,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 9, 40, 17, 124841)}
2017-10-17 17:40:21 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 19:12:20 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 19:12:20 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 19:12:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 19:12:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 19:12:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 19:12:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 19:12:20 [scrapy.core.engine] INFO: Spider opened
2017-10-17 19:12:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print (time if time < 7 else 0)
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:22 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 19:12:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 54436,
 'downloader/request_count': 188,
 'downloader/request_method_count/GET': 188,
 'downloader/response_bytes': 1042669,
 'downloader/response_count': 188,
 'downloader/response_status_count/200': 188,
 'dupefilter/filtered': 79,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 11, 12, 22, 616665),
 'log_count/DEBUG': 189,
 'log_count/ERROR': 156,
 'log_count/INFO': 7,
 'memusage/max': 22671360,
 'memusage/startup': 22671360,
 'request_depth_max': 4,
 'response_received_count': 188,
 'scheduler/dequeued': 188,
 'scheduler/dequeued/memory': 188,
 'scheduler/enqueued': 188,
 'scheduler/enqueued/memory': 188,
 'spider_exceptions/TypeError': 156,
 'start_time': datetime.datetime(2017, 10, 17, 11, 12, 20, 150932)}
2017-10-17 19:12:22 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 19:12:44 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 19:12:44 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 19:12:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 19:12:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 19:12:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 19:12:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 19:12:44 [scrapy.core.engine] INFO: Spider opened
2017-10-17 19:12:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 60, in parse_1
    print time if time < 7 else 0
TypeError: can't compare datetime.timedelta to int
2017-10-17 19:12:46 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 19:12:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 54436,
 'downloader/request_count': 188,
 'downloader/request_method_count/GET': 188,
 'downloader/response_bytes': 1042669,
 'downloader/response_count': 188,
 'downloader/response_status_count/200': 188,
 'dupefilter/filtered': 78,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 11, 12, 46, 837695),
 'log_count/DEBUG': 189,
 'log_count/ERROR': 157,
 'log_count/INFO': 7,
 'memusage/max': 22577152,
 'memusage/startup': 22577152,
 'request_depth_max': 4,
 'response_received_count': 188,
 'scheduler/dequeued': 188,
 'scheduler/dequeued/memory': 188,
 'scheduler/enqueued': 188,
 'scheduler/enqueued/memory': 188,
 'spider_exceptions/TypeError': 157,
 'start_time': datetime.datetime(2017, 10, 17, 11, 12, 44, 387978)}
2017-10-17 19:12:46 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 19:13:44 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 19:13:44 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 19:13:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 19:13:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 19:13:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 19:13:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 19:13:44 [scrapy.core.engine] INFO: Spider opened
2017-10-17 19:13:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 19:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:13:48 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 19:13:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 11, 13, 48, 245325),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22626304,
 'memusage/startup': 22626304,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 11, 13, 44, 67994)}
2017-10-17 19:13:48 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 19:15:36 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 19:15:36 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 19:15:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 19:15:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 19:15:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 19:15:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 19:15:36 [scrapy.core.engine] INFO: Spider opened
2017-10-17 19:15:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/hefeng.py", line 61, in parse_1
    print time.seconds()
TypeError: 'int' object is not callable
2017-10-17 19:15:38 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 19:15:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 54436,
 'downloader/request_count': 188,
 'downloader/request_method_count/GET': 188,
 'downloader/response_bytes': 1042669,
 'downloader/response_count': 188,
 'downloader/response_status_count/200': 188,
 'dupefilter/filtered': 76,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 11, 15, 38, 856272),
 'log_count/DEBUG': 189,
 'log_count/ERROR': 159,
 'log_count/INFO': 7,
 'memusage/max': 22421504,
 'memusage/startup': 22421504,
 'request_depth_max': 4,
 'response_received_count': 188,
 'scheduler/dequeued': 188,
 'scheduler/dequeued/memory': 188,
 'scheduler/enqueued': 188,
 'scheduler/enqueued/memory': 188,
 'spider_exceptions/TypeError': 159,
 'start_time': datetime.datetime(2017, 10, 17, 11, 15, 36, 470333)}
2017-10-17 19:15:38 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 19:16:42 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 19:16:42 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 19:16:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 19:16:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 19:16:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 19:16:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 19:16:42 [scrapy.core.engine] INFO: Spider opened
2017-10-17 19:16:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 19:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:16:46 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 19:16:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 11, 16, 46, 396939),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22499328,
 'memusage/startup': 22499328,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 11, 16, 42, 138660)}
2017-10-17 19:16:46 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 19:19:49 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 19:19:49 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 19:19:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 19:19:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 19:19:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 19:19:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 19:19:49 [scrapy.core.engine] INFO: Spider opened
2017-10-17 19:19:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:19:53 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 19:19:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 11, 19, 53, 409825),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22683648,
 'memusage/startup': 22683648,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 11, 19, 49, 173838)}
2017-10-17 19:19:53 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 19:21:06 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 19:21:06 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 19:21:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 19:21:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 19:21:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 19:21:06 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 19:21:06 [scrapy.core.engine] INFO: Spider opened
2017-10-17 19:21:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 19:21:10 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 19:21:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 11, 21, 10, 722500),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22614016,
 'memusage/startup': 22614016,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 11, 21, 6, 424468)}
2017-10-17 19:21:10 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 19:21:54 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 19:21:54 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 19:21:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 19:21:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 19:21:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 19:21:54 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 19:21:54 [scrapy.core.engine] INFO: Spider opened
2017-10-17 19:21:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 19:21:59 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 19:21:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190829,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 11, 21, 59, 64188),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22614016,
 'memusage/startup': 22614016,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 11, 21, 54, 544833)}
2017-10-17 19:21:59 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 20:14:40 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 20:14:40 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 20:14:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 20:14:40 [twisted] ERROR: Unhandled error in Deferred:
2017-10-17 20:14:40 [twisted] ERROR: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/commands/crawl.py", line 57, in run
    self.crawler_process.crawl(spname, **opts.spargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 168, in crawl
    return self._crawl(crawler, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 172, in _crawl
    d = crawler.crawl(*args, **kwargs)
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1237, in unwindGenerator
    return _inlineCallbacks(None, gen, Deferred())
--- <exception caught here> ---
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1099, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 95, in crawl
    six.reraise(*exc_info)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 76, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 99, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 100, in from_crawler
    spider = super(CrawlSpider, cls).from_crawler(crawler, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/__init__.py", line 51, in from_crawler
    spider = cls(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 40, in __init__
    self._compile_rules()
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 92, in _compile_rules
    self._rules = [copy.copy(r) for r in self.rules]
exceptions.TypeError: 'Rule' object is not iterable

2017-10-17 20:15:53 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 20:15:53 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 20:15:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 20:15:53 [twisted] ERROR: Unhandled error in Deferred:
2017-10-17 20:15:53 [twisted] ERROR: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/commands/crawl.py", line 57, in run
    self.crawler_process.crawl(spname, **opts.spargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 168, in crawl
    return self._crawl(crawler, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 172, in _crawl
    d = crawler.crawl(*args, **kwargs)
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1237, in unwindGenerator
    return _inlineCallbacks(None, gen, Deferred())
--- <exception caught here> ---
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1099, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 95, in crawl
    six.reraise(*exc_info)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 76, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 99, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 100, in from_crawler
    spider = super(CrawlSpider, cls).from_crawler(crawler, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/__init__.py", line 51, in from_crawler
    spider = cls(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 40, in __init__
    self._compile_rules()
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 92, in _compile_rules
    self._rules = [copy.copy(r) for r in self.rules]
exceptions.TypeError: 'Rule' object is not iterable

2017-10-17 20:17:26 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 20:17:26 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 20:17:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 20:17:26 [twisted] ERROR: Unhandled error in Deferred:
2017-10-17 20:17:26 [twisted] ERROR: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/commands/crawl.py", line 57, in run
    self.crawler_process.crawl(spname, **opts.spargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 168, in crawl
    return self._crawl(crawler, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 172, in _crawl
    d = crawler.crawl(*args, **kwargs)
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1237, in unwindGenerator
    return _inlineCallbacks(None, gen, Deferred())
--- <exception caught here> ---
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1099, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 95, in crawl
    six.reraise(*exc_info)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 76, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 99, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 100, in from_crawler
    spider = super(CrawlSpider, cls).from_crawler(crawler, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/__init__.py", line 51, in from_crawler
    spider = cls(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 40, in __init__
    self._compile_rules()
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 92, in _compile_rules
    self._rules = [copy.copy(r) for r in self.rules]
exceptions.TypeError: 'Rule' object is not iterable

2017-10-17 20:21:25 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 20:21:25 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 20:21:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 20:21:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 20:21:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 20:21:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 20:21:25 [scrapy.core.engine] INFO: Spider opened
2017-10-17 20:21:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 20:21:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index_4.jhtml> (referer: None)
2017-10-17 20:21:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index.jhtml> (referer: None)
2017-10-17 20:21:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index_3.jhtml> (referer: None)
2017-10-17 20:21:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index_2.jhtml> (referer: None)
2017-10-17 20:21:27 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xfxw.com.cn:80/yaowen/93856.jhtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 20:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97352.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67523.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/66440.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67048.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97352.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67523.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/66440.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/42526.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67048.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/68705.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67313.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/62855.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/42526.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/68705.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67313.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/62855.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/64236.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/65436.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/60511.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98340.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/64236.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/65436.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/60511.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98340.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98345.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98493.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98520.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98345.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98493.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98520.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97871.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97879.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97885.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97882.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97871.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97879.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97885.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97882.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98015.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98009.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98006.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98012.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98015.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98009.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98006.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98012.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:36 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2017-10-17 20:21:36 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-10-17 20:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98133.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98018.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98133.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98018.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98167.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97447.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97355.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:37 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2017-10-17 20:21:39 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 20:21:39 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 20:21:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 20:21:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 20:21:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 20:21:39 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 20:21:39 [scrapy.core.engine] INFO: Spider opened
2017-10-17 20:21:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 20:21:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index.jhtml> (referer: None)
2017-10-17 20:21:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index_3.jhtml> (referer: None)
2017-10-17 20:21:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index_4.jhtml> (referer: None)
2017-10-17 20:21:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index_2.jhtml> (referer: None)
2017-10-17 20:21:41 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xfxw.com.cn:80/yaowen/93856.jhtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 20:21:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97352.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98331.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97352.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98331.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67313.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97868.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67313.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67048.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67523.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97868.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/66440.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67048.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67523.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/66440.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93856.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93856.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/42526.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/42526.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/68705.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/62855.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/68705.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/62855.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/64236.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/64236.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98334.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/65436.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/60511.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98334.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/65436.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/60511.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98337.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98337.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97871.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97871.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97879.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97879.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97882.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97882.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97885.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97885.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98006.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98006.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98009.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98012.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98009.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98012.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98015.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98015.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98018.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98133.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98167.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:21:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98018.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98133.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98167.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/96923.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/96923.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/96932.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/96932.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97016.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97005.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97078.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97016.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97005.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97078.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97108.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97219.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97180.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97108.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97219.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97180.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97225.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97225.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97235.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97235.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97447.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97447.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97355.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97355.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97453.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97453.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97450.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97456.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97459.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97450.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97456.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97459.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97644.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97644.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97650.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97650.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97653.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97653.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97656.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97656.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98345.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97895.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:21:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98340.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98345.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97895.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98340.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98493.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:21:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98493.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:21:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98520.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98599.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98520.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98599.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93867.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93867.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93861.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93861.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93864.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93864.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:01 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 20:22:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 19156,
 'downloader/request_count': 62,
 'downloader/request_method_count/GET': 62,
 'downloader/response_bytes': 2135822,
 'downloader/response_count': 62,
 'downloader/response_status_count/200': 62,
 'dupefilter/filtered': 60,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 12, 22, 1, 109149),
 'log_count/DEBUG': 63,
 'log_count/ERROR': 58,
 'log_count/INFO': 7,
 'memusage/max': 22638592,
 'memusage/startup': 22638592,
 'request_depth_max': 1,
 'response_received_count': 62,
 'scheduler/dequeued': 62,
 'scheduler/dequeued/memory': 62,
 'scheduler/enqueued': 62,
 'scheduler/enqueued/memory': 62,
 'spider_exceptions/AttributeError': 58,
 'start_time': datetime.datetime(2017, 10, 17, 12, 21, 39, 284950)}
2017-10-17 20:22:01 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 20:22:23 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 20:22:23 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 20:22:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 20:22:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 20:22:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 20:22:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 20:22:23 [scrapy.core.engine] INFO: Spider opened
2017-10-17 20:22:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 20:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index.jhtml> (referer: None)
2017-10-17 20:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index_2.jhtml> (referer: None)
2017-10-17 20:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index_3.jhtml> (referer: None)
2017-10-17 20:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index_4.jhtml> (referer: None)
2017-10-17 20:22:25 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xfxw.com.cn:80/yaowen/93856.jhtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 20:22:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/66440.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67523.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67048.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/66440.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67523.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67048.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67313.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/42526.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/68705.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/62855.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67313.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/42526.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/68705.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/62855.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93856.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93856.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/65436.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/64236.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/60511.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/65436.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/64236.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/60511.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98334.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98337.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98345.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98334.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98337.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98345.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98340.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98340.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/96932.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/96923.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/96932.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/96923.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97005.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97078.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97016.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97005.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97078.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97016.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97108.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97180.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97108.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97180.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97219.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97219.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97225.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97235.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97225.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97235.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97355.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97355.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97352.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
2017-10-17 20:22:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97450.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97447.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97352.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_4.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97450.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97447.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97453.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97453.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97456.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97459.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97456.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97459.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97644.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97650.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97644.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97650.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97653.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97653.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97895.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97656.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97895.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97656.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97868.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
2017-10-17 20:22:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97868.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_3.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97871.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97879.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97871.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97879.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97882.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/97885.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97882.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98006.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/97885.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98006.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98012.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98012.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98009.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98009.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98015.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98015.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98018.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98018.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98133.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98167.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98133.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98167.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98493.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98331.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
2017-10-17 20:22:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98493.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98331.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index_2.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98599.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98520.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98599.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98520.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93867.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93867.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93864.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93861.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:22:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93864.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93861.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 48, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:22:44 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 20:22:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 19156,
 'downloader/request_count': 62,
 'downloader/request_method_count/GET': 62,
 'downloader/response_bytes': 2135822,
 'downloader/response_count': 62,
 'downloader/response_status_count/200': 62,
 'dupefilter/filtered': 60,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 12, 22, 44, 997785),
 'log_count/DEBUG': 63,
 'log_count/ERROR': 58,
 'log_count/INFO': 7,
 'memusage/max': 22441984,
 'memusage/startup': 22441984,
 'request_depth_max': 1,
 'response_received_count': 62,
 'scheduler/dequeued': 62,
 'scheduler/dequeued/memory': 62,
 'scheduler/enqueued': 62,
 'scheduler/enqueued/memory': 62,
 'spider_exceptions/AttributeError': 58,
 'start_time': datetime.datetime(2017, 10, 17, 12, 22, 23, 934404)}
2017-10-17 20:22:44 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 20:24:18 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 20:24:18 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 20:24:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 20:24:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 20:24:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 20:24:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 20:24:18 [scrapy.core.engine] INFO: Spider opened
2017-10-17 20:24:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 20:24:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:24:22 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 20:24:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190812,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 12, 24, 22, 936070),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22728704,
 'memusage/startup': 22728704,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 12, 24, 18, 739171)}
2017-10-17 20:24:22 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 20:50:19 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 20:50:19 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 20:50:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 20:50:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 20:50:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 20:50:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 20:50:20 [scrapy.core.engine] INFO: Spider opened
2017-10-17 20:50:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:50:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 20:50:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 20:50:24 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 20:50:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190812,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 12, 50, 24, 348859),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22437888,
 'memusage/startup': 22437888,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 12, 50, 20, 41276)}
2017-10-17 20:50:24 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 20:53:15 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 20:53:15 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 20:53:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 20:53:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 20:53:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 20:53:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 20:53:15 [scrapy.core.engine] INFO: Spider opened
2017-10-17 20:53:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: None)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591362.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591366.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591336.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591379.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591377.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591383.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591381.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591630.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.enshi.gov.cn/2017/1017/591779.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591708.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1016/591735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591773.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591771.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591774.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1017/591776.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590569.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588874.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/1.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589222.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589852.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591308.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589858.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589862.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590065.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590073.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588877.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588882.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588892.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588896.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588903.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590076.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590080.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590082.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588905.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588909.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588914.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588920.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588921.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589186.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589194.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589199.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586015.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586017.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586029.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586034.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586037.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586038.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586040.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586044.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586047.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586051.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0925/586052.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586302.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586309.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586313.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586317.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586320.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586322.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586323.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585391.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585397.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585398.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585399.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585400.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585722.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585724.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0922/585728.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585944.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585946.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585948.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585951.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585952.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585956.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585961.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586324.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/7.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0923/585995.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/8.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589203.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589208.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589210.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589212.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589216.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589218.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/5.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589226.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589637.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589640.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589642.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589644.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589660.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589661.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589666.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589676.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589687.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0929/589688.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0930/589669.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589719.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1001/589720.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1003/589762.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589848.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1009/589851.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/4.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590727.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590731.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590735.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590737.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1012/590739.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590972.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590975.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590977.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590979.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590981.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590985.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590987.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590990.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1013/590992.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591289.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0918/584409.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584707.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584710.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584714.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584717.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584721.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/584726.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0919/585053.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582589.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583730.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0914/583759.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0916/584347.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588949.shtml> (referer: http://www.enshi.gov.cn/2017/0929/589636.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585054.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585057.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585059.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585063.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585064.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/584849.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585067.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585068.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585071.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585075.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0920/585078.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0921/585384.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/9.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591299.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591303.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591304.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1014/591305.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/2.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590085.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590089.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590090.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590096.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590103.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1010/590202.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590364.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590368.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590371.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590372.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/1011/590374.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/3.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586332.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586334.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0926/586373.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586605.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586610.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586617.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586623.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586629.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0819/578495.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0908/582543.shtml> (referer: http://www.enshi.gov.cn/2017/0908/582589.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586631.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586636.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586638.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586643.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586645.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586648.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586664.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0927/586652.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588855.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588860.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.enshi.gov.cn/2017/0928/588869.shtml> (referer: http://www.enshi.gov.cn/zzf/xw/esxw/6.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0918/584653.shtml> (referer: http://www.enshi.gov.cn/2017/0920/585067.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590237.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590692.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591994.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591257.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590966.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590965.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590312.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590967.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1017/591998.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/0930/589712.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590309.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1010/590324.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590969.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1011/590596.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591150.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590968.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1012/590970.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1013/591151.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eszrsj.gov.cn/2017/1016/591474.shtml> (referer: http://www.eszrsj.gov.cn/2017/0918/584653.shtml)
2017-10-17 20:53:19 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 20:53:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 62386,
 'downloader/request_count': 215,
 'downloader/request_method_count/GET': 215,
 'downloader/response_bytes': 1190812,
 'downloader/response_count': 215,
 'downloader/response_status_count/200': 215,
 'dupefilter/filtered': 619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 12, 53, 19, 834934),
 'log_count/DEBUG': 216,
 'log_count/INFO': 7,
 'memusage/max': 22654976,
 'memusage/startup': 22654976,
 'request_depth_max': 7,
 'response_received_count': 215,
 'scheduler/dequeued': 215,
 'scheduler/dequeued/memory': 215,
 'scheduler/enqueued': 215,
 'scheduler/enqueued/memory': 215,
 'start_time': datetime.datetime(2017, 10, 17, 12, 53, 15, 503354)}
2017-10-17 20:53:19 [scrapy.core.engine] INFO: Spider closed (finished)
2017-10-17 20:57:09 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: tutorial)
2017-10-17 20:57:09 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tutorial.spiders', 'SPIDER_MODULES': ['tutorial.spiders'], 'LOG_FILE': 'log.txt', 'BOT_NAME': 'tutorial'}
2017-10-17 20:57:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-10-17 20:57:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-10-17 20:57:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-10-17 20:57:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-10-17 20:57:09 [scrapy.core.engine] INFO: Spider opened
2017-10-17 20:57:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-10-17 20:57:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn/yaowen/index.jhtml> (referer: None)
2017-10-17 20:57:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/66440.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67048.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/68705.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/62855.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/66440.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67048.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/68705.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/62855.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67313.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/67523.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67313.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/67523.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93856.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93856.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/42526.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/42526.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/60511.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/60511.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98337.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/64236.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98340.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98337.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/65436.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/64236.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98340.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/65436.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98334.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98334.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98349.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98345.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98345.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98493.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98520.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93867.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98493.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/98599.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98520.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93867.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/98599.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93861.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xfxw.com.cn:80/yaowen/93864.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
2017-10-17 20:57:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93861.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.xfxw.com.cn:80/yaowen/93864.jhtml> (referer: http://www.xfxw.com.cn/yaowen/index.jhtml)
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/home/tutorial/tutorial/spiders/xianfengnews.py", line 45, in parse_1
    print title.enshi('UTF_8')
AttributeError: 'unicode' object has no attribute 'enshi'
2017-10-17 20:57:19 [scrapy.core.engine] INFO: Closing spider (finished)
2017-10-17 20:57:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7117,
 'downloader/request_count': 23,
 'downloader/request_method_count/GET': 23,
 'downloader/response_bytes': 1183207,
 'downloader/response_count': 23,
 'downloader/response_status_count/200': 23,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 10, 17, 12, 57, 19, 346363),
 'log_count/DEBUG': 23,
 'log_count/ERROR': 22,
 'log_count/INFO': 7,
 'memusage/max': 22478848,
 'memusage/startup': 22478848,
 'request_depth_max': 1,
 'response_received_count': 23,
 'scheduler/dequeued': 23,
 'scheduler/dequeued/memory': 23,
 'scheduler/enqueued': 23,
 'scheduler/enqueued/memory': 23,
 'spider_exceptions/AttributeError': 22,
 'start_time': datetime.datetime(2017, 10, 17, 12, 57, 9, 220820)}
2017-10-17 20:57:19 [scrapy.core.engine] INFO: Spider closed (finished)
